{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de Dados em Texto\n",
    "\n",
    "Objetivo: a partir de técnicas de contagem, visualizar e interpretar os dados.\n",
    "Parte do material baseado em https://github.com/JasonKessler/scattertext#emoji-analysis\n",
    "\n",
    "\"A tool for finding distinguishing terms in corpora, and presenting them in an interactive, HTML scatter plot. Points corresponding to terms are selectively labeled so that they don't overlap with other labels or points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, pkgutil, json, urllib\n",
    "import scattertext as st\n",
    "import re, io\n",
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "from   scipy.stats          import rankdata, hmean, norm\n",
    "from   pprint               import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "from   urllib.request       import urlopen\n",
    "from   IPython.display      import IFrame\n",
    "from   IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')# ou ('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de Dados: Republicanos e Democratas\n",
    "\n",
    "Discursos de democratas e republicanos em 2012 (eleição). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. Thank you. Thank you. Thank you so ...</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you so much. Tonight, I am so thrilled a...</td>\n",
       "      <td>MICHELLE OBAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. It is a singular honor to be here t...</td>\n",
       "      <td>RICHARD DURBIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hey, Delaware. \\nAnd my favorite Democrat, Jil...</td>\n",
       "      <td>JOSEPH BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hello. \\nThank you, Angie. I'm so proud of how...</td>\n",
       "      <td>JILL BIDEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      party                                               text         speaker\n",
       "0  democrat  Thank you. Thank you. Thank you. Thank you so ...    BARACK OBAMA\n",
       "1  democrat  Thank you so much. Tonight, I am so thrilled a...  MICHELLE OBAMA\n",
       "2  democrat  Thank you. It is a singular honor to be here t...  RICHARD DURBIN\n",
       "3  democrat  Hey, Delaware. \\nAnd my favorite Democrat, Jil...    JOSEPH BIDEN\n",
       "4  democrat  Hello. \\nThank you, Angie. I'm so proud of how...      JILL BIDEN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algumas estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contando documentos\n",
      "\n",
      "party\n",
      "democrat      123\n",
      "republican     66\n",
      "Name: text, dtype: int64\n",
      "\n",
      "Contando palavras\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "party\n",
       "democrat      76843\n",
       "republican    58144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nContando documentos\\n\")\n",
    "print(convention_df.groupby('party')['text'].count())\n",
    "\n",
    "print(\"\\nContando palavras\")\n",
    "convention_df.groupby('party').apply(lambda x: x.text.apply(lambda x: len(x.split())).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando NLP com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df['parsed'] = convention_df.text.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. Thank you. Thank you. Thank you so ...</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "      <td>(Thank, you, ., Thank, you, ., Thank, you, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you so much. Tonight, I am so thrilled a...</td>\n",
       "      <td>MICHELLE OBAMA</td>\n",
       "      <td>(Thank, you, so, much, ., Tonight, ,, I, am, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. It is a singular honor to be here t...</td>\n",
       "      <td>RICHARD DURBIN</td>\n",
       "      <td>(Thank, you, ., It, is, a, singular, honor, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hey, Delaware. \\nAnd my favorite Democrat, Jil...</td>\n",
       "      <td>JOSEPH BIDEN</td>\n",
       "      <td>(Hey, ,, Delaware, ., \\n, And, my, favorite, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hello. \\nThank you, Angie. I'm so proud of how...</td>\n",
       "      <td>JILL BIDEN</td>\n",
       "      <td>(Hello, ., \\n, Thank, you, ,, Angie, ., I, 'm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      party                                               text  \\\n",
       "0  democrat  Thank you. Thank you. Thank you. Thank you so ...   \n",
       "1  democrat  Thank you so much. Tonight, I am so thrilled a...   \n",
       "2  democrat  Thank you. It is a singular honor to be here t...   \n",
       "3  democrat  Hey, Delaware. \\nAnd my favorite Democrat, Jil...   \n",
       "4  democrat  Hello. \\nThank you, Angie. I'm so proud of how...   \n",
       "\n",
       "          speaker                                             parsed  \n",
       "0    BARACK OBAMA  (Thank, you, ., Thank, you, ., Thank, you, ., ...  \n",
       "1  MICHELLE OBAMA  (Thank, you, so, much, ., Tonight, ,, I, am, s...  \n",
       "2  RICHARD DURBIN  (Thank, you, ., It, is, a, singular, honor, to...  \n",
       "3    JOSEPH BIDEN  (Hey, ,, Delaware, ., \\n, And, my, favorite, D...  \n",
       "4      JILL BIDEN  (Hello, ., \\n, Thank, you, ,, Angie, ., I, 'm,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (Thank, you, ., Thank, you, ., Thank, you, ., ...\n",
       "1      (Thank, you, so, much, ., Tonight, ,, I, am, s...\n",
       "2      (Thank, you, ., It, is, a, singular, honor, to...\n",
       "3      (Hey, ,, Delaware, ., \\n, And, my, favorite, D...\n",
       "4      (Hello, ., \\n, Thank, you, ,, Angie, ., I, 'm,...\n",
       "                             ...                        \n",
       "184    (As, the, elected, leader, of, 250,000, Colleg...\n",
       "185    (Good, afternoon, ., I, 'm, Pete, Sessions, ,,...\n",
       "186    (To, Chairman, Priebus, and, to, my, fellow, A...\n",
       "187    (\\n, Absolutely, ., Thank, you, ,, Mr, ., Chai...\n",
       "188    (I, am, thrilled, to, add, Utah, 's, voice, in...\n",
       "Name: parsed, Length: 189, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df['parsed']                    #[0][0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando em um Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = st.CorpusFromParsedDocuments(convention_df, category_col='party', parsed_col='parsed').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando termos por uma métrica de frequência\n",
    "\n",
    "#####  Termos (até duplas de termos) mais usados por candidatos republicanos e democratas, qual a frequência cada palavra é usada com base em 25k palavras e um score de relevância associado. \n",
    "\n",
    "Existe uma variante para frases neste mesmo pacote em: https://github.com/JasonKessler/scattertext#using-phrasemachine-to-find-phrases que são as phrase machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"1000\"\n",
       "            src=\"Convention-Visualization.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a8b51b630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "          category          = 'democrat',\n",
    "          category_name     = 'Democratic',\n",
    "          not_category_name = 'Republican',\n",
    "          width_in_pixels   = 800,\n",
    "          height_in_pixels  = 500,\n",
    "          metadata=convention_df['speaker'])\n",
    "\n",
    "file_name = \"Convention-Visualization.html\"\n",
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 700, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Características do Corpus \n",
    "\n",
    "Often the terms of most interest are ones that are characteristic to the corpus as a whole. These are terms which occur frequently in all sets of documents being studied, but relatively infrequent compared to general term frequencies.\n",
    "\n",
    "We can produce a plot with a characteristic score on the x-axis and class-association scores on the y-axis using the function produce_characteristic_explorer.\n",
    "\n",
    "Corpus characteristicness is the difference in dense term ranks between the words in all of the documents in the study and a general English-language frequency list. See this Talk on Term-Class Association Scores for a more thorough explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"1000\"\n",
       "            src=\"demo_characteristic_chart.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a9dd0eef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scattertext as st\n",
    "\n",
    "corpus = (st.CorpusFromPandas(st.SampleCorpora.ConventionData2012.get_data(),\n",
    "                              category_col='party',\n",
    "                              text_col='text',\n",
    "                              nlp=st.whitespace_nlp_with_sentences)\n",
    "                              .build()\n",
    "                              .get_unigram_corpus()\n",
    "                              .compact(st.ClassPercentageCompactor(term_count=2,\n",
    "                                       term_ranker=st.OncePerDocFrequencyRanker)))\n",
    "\n",
    "html = st.produce_characteristic_explorer(\n",
    "                                corpus,\n",
    "                                category          = 'democrat',\n",
    "                                category_name     = 'Democratic',\n",
    "                                not_category_name = 'Republican',\n",
    "                                width_in_pixels   = 800,\n",
    "                                height_in_pixels  = 500,\n",
    "                                metadata=corpus.get_df()['speaker']\n",
    ")\n",
    "\n",
    "file_name = 'demo_characteristic_chart.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 700, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizando termos relacionados à empatia\n",
    "\n",
    "In order to visualize Empath (Fast et al., 2016) topics and categories instead of terms, we'll need to create a Corpus of extracted topics and categories rather than unigrams and bigrams. To do so, use the FeatsOnlyFromEmpath feature extractor. See the source code for examples of how to make your own.\n",
    "\n",
    "When creating the visualization, pass the use_non_text_features=True argument into produce_scattertext_explorer. This will instruct it to use the labeled Empath topics and categories instead of looking for terms. Since the documents returned when a topic or category label is clicked will be in order of the document-level category-association strength, setting use_full_doc=True makes sense, unless you have enormous documents. Otherwise, the first 300 characters will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"1000\"\n",
       "            src=\"Convention-Visualization-Empath.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a8549e198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_builder  = st.FeatsFromOnlyEmpath()\n",
    "empath_corpus = st.CorpusFromParsedDocuments(convention_df,\n",
    "                                              category_col='party',\n",
    "                                              feats_from_spacy_doc=feat_builder,\n",
    "                                              parsed_col='text').build()\n",
    "\n",
    "html = st.produce_scattertext_explorer(empath_corpus,\n",
    "                                        category='democrat',\n",
    "                                        category_name='Democratic',\n",
    "                                        not_category_name='Republican',\n",
    "                                        width_in_pixels=800,\n",
    "                                        height_in_pixels=500,\n",
    "                                        metadata=convention_df['speaker'],\n",
    "                                        use_non_text_features=True,\n",
    "                                        use_full_doc=True,\n",
    "                                        topic_model_term_lists=feat_builder.get_top_model_term_lists())\n",
    "\n",
    "file_name = \"Convention-Visualization-Empath.html\"\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 700, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando termos com relação à moralidade\n",
    "\n",
    "The [Moral Foundations Theory] proposes six psychological constructs as building blocks of moral thinking, as described in Graham et al. (2013). These foundations are, as described on [moralfoundations.org]: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, sanctity/degradation, and liberty/oppression. Please see the site for a more in-depth discussion of these foundations.\n",
    "\n",
    "Frimer et al. (2019) created the Moral Foundations Dictionary 2.0, or a lexicon of terms which invoke a moral foundation as a virtue (favorable toward the foundation) or a vice (in opposition to the foundation).\n",
    "\n",
    "This dictionary can be used in the same way as the General Inquirer. In this example, we can plot the Cohen's d scores of foundation-word counts relative to the frequencies words involving those foundations were invoked.\n",
    "\n",
    "We can first load the the corpus as normal, and use st.FeatsFromMoralFoundationsDictionary() to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df           = st.SampleCorpora.ConventionData2012.get_data()\n",
    "moral_foundations_feats = st.FeatsFromMoralFoundationsDictionary()\n",
    "corpus                  = st.CorpusFromPandas(convention_df,\n",
    "                             category_col='party',\n",
    "                             text_col='text',\n",
    "                             nlp=st.whitespace_nlp_with_sentences,\n",
    "                             feats_from_spacy_doc=moral_foundations_feats).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    corpus,\n",
    "    category='democrat',\n",
    "    category_name='Democratic',\n",
    "    not_category_name='Republican',\n",
    "    metadata=convention_df['speaker'],\n",
    "    use_non_text_features=True,\n",
    "    use_full_doc=True,\n",
    "    term_scorer=st.CohensD(corpus).use_metadata(),\n",
    "    grey_threshold=0,\n",
    "    width_in_pixels=800,\n",
    "    height_in_pixels=500,\n",
    "    topic_model_term_lists=moral_foundations_feats.get_top_model_term_lists(),                \n",
    "    metadata_descriptions=moral_foundations_feats.get_definitions()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"Convention-Visualization-Morality.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a9a5129b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"Convention-Visualization-Morality.html\"\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando termos no espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parse'] = convention_df['text'].apply(st.whitespace_nlp_with_sentences)\n",
    "\n",
    "corpus = (st.CorpusFromParsedDocuments(convention_df, category_col='party', parsed_col='parse')\n",
    "          .build().get_stoplisted_unigram_corpus())\n",
    "\n",
    "html = st.produce_projection_explorer(corpus, category='democrat', category_name='Democratic',\n",
    "  not_category_name='Republican', metadata=convention_df.speaker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"Convention-Visualization-general.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20a9eaf5978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"Convention-Visualization-general.html\"\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avançado\n",
    "\n",
    "Necessita de treino de modelo e entendimento de embeddings.\n",
    "\n",
    "#### Como democratas e republicanos se referem à palavra Job ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from scattertext import SampleCorpora, word_similarity_explorer_gensim, Word2VecFromParsedCorpus\n",
    "from scattertext.CorpusFromParsedDocuments import CorpusFromParsedDocuments\n",
    "\n",
    "convention_df           = SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parsed'] = convention_df.text.apply(nlp)\n",
    "corpus                  = CorpusFromParsedDocuments(convention_df, category_col='party', parsed_col='parsed').build()\n",
    "\n",
    "# transforma palavras em vetores\n",
    "model = word2vec.Word2Vec(size=300,\n",
    "                          alpha=0.025,\n",
    "                          window=5,\n",
    "                          min_count=5,\n",
    "                          max_vocab_size=None,\n",
    "                          sample=0,\n",
    "                          seed=1,\n",
    "                          workers=1,\n",
    "                          min_alpha=0.0001,\n",
    "                          sg=1,\n",
    "                          hs=1,\n",
    "                          negative=0,\n",
    "                          cbow_mean=0,\n",
    "                          iter=1,\n",
    "                          null_word=0,\n",
    "                          trim_rule=None,\n",
    "                          sorted_vocab=1)\n",
    "\n",
    "html = word_similarity_explorer_gensim(corpus,\n",
    "                                       category='democrat',\n",
    "                                       category_name='Democratic',\n",
    "                                       not_category_name='Republican',\n",
    "                                       target_term='jobs',\n",
    "                                       minimum_term_frequency=5,\n",
    "                                       pmi_threshold_coefficient=4,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       metadata=convention_df['speaker'],\n",
    "                                       word2vec=Word2VecFromParsedCorpus(corpus, model).train(),\n",
    "                                       max_p_val=0.05,\n",
    "                                       save_svg_button=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"Convention-Visualization-JOB.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20aacae46d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"Convention-Visualization-JOB.html\"\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "IFrame(src=file_name, width = 1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
